# The temperature parameter controls the randomness of the model's output. Lower values make the output more deterministic.
temperature = 0.1

# The maximum number of new tokens that the model can generate.
max_tokens = 1024

# The start separator for the generated code.
start_sep = ```

# The end separator for the generated code.
end_sep = ```

# If True, the first line of the generated text will be skipped.
skip_first_line = True

# The model used for generating the code.
HF_MODEL = mistralai/Mistral-7B-Instruct-v0.1